Vector stores in LangChain store document embeddings for efficient retrieval in RAG applications. They use embeddings (e.g., from HuggingFace models) to convert text into vectors, enabling similarity searches. Common vector stores include FAISS and Chroma. They are used for tasks like question answering, where relevant documents are retrieved based on query embeddings and passed to an LLM for answer generation.